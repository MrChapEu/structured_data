{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "#from keras.applications.imagenet_utils import preprocess_input\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on a batch of images\n",
    "\n",
    "The predict_batch function is defined as follows:\n",
    "\n",
    "    - open each image, and resize them to img_size\n",
    "    - stack them as a batch tensor of shape (batch, img_size_x, img_size_y)\n",
    "    - preprocess the batch and make a forward pass with the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def predict_batch(model, img_batch_path, img_size=None):\n",
    "def predict_batch(folder, img_size=None):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        \n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img = imread(os.path.join(folder,filename))\n",
    "            lb = filename.split('_')[1]\n",
    "            lb = lb.lower()\n",
    "        \n",
    "        if img_size:\n",
    "            img = imresize(img,img_size)\n",
    "\n",
    "        img = img.astype('float32')\n",
    "        \n",
    "        # convert image to greyscale\n",
    "        img = img.sum(axis=2) / 3.\n",
    "        img /= np.std(img)\n",
    "        \n",
    "        img = img[:, :, np.newaxis]\n",
    "        \n",
    "        img_list.append(img)\n",
    "        label_list.append(lb)\n",
    "    try:\n",
    "        img_batch = np.stack(img_list, axis=0)\n",
    "    except:\n",
    "        raise ValueError(\n",
    "            'when both img_size and crop_size are None, all images '\n",
    "            'in image_paths must have the same shapes.')\n",
    "\n",
    "    #batch = preprocess_input(img_batch)\n",
    "    return img_batch, label_list \n",
    "            #model.predict(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape (523, 32, 100, 1)\n",
      "label shape 523\n"
     ]
    }
   ],
   "source": [
    "YOUR_FOLDER_NAME = \"try\"\n",
    "\n",
    "output, labels = predict_batch(YOUR_FOLDER_NAME, (32, 100))\n",
    "print(\"output shape\", output.shape)\n",
    "print ('label shape', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 100, 1)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output[0][:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x37e7c4320>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACOCAYAAAAhHfOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x37dbbf400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1][:,:,0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv-net model\n",
    "\n",
    "The base CNN has five convolutional layers and two fully connected layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras as ks\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras.layers import Flatten, Dropout, MaxPooling2D,Input\n",
    "from keras.layers import Dense, InputLayer, Convolution2D\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def squeeze_dim(x, axis=-1):\n",
    "    # Removes a 1-dimension from the tensor at index \"axis\"\n",
    "    return K.squeeze(x, axis=axis)\n",
    "\n",
    "\n",
    "class CNN(object):\n",
    "    \"\"\"\n",
    "    Usage for tf tensor output:\n",
    "    o = CNN(x).tf_output()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_tensor):\n",
    "        self._build_network(input_tensor)\n",
    "\n",
    "    def _build_network(self, input_tensor):\n",
    "        \n",
    "        model_input = Input(shape=(32,100,1))#,tensor=input_tensor)\n",
    "\n",
    "        conv_layers_size = [64,128,256,512,512]\n",
    "        edges_size = [5,5,3,3,3]\n",
    "        \n",
    "        #convolutional layes\n",
    "        x = model_input \n",
    "        for i,(layer_size, edge_size) in enumerate(zip(conv_layers_size,edges_size)):\n",
    "            x = Convolution2D(\n",
    "                layer_size, edge_size, edge_size, \n",
    "                activation='relu', subsample=(1, 1),border_mode='same')(x)\n",
    "            if i <= 2 :\n",
    "                x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "        #dense layers\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(4096, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(4096)(x)\n",
    "    \n",
    "    \n",
    "        N = 23\n",
    "        outputs = []\n",
    "        for i in range(N):\n",
    "            outputs.append(Dense(37,activation='softmax')(x))\n",
    "        \n",
    "        self.model = Model(input=model_input,output=outputs)\n",
    "\n",
    "    def tf_output(self):\n",
    "        # if self.input_tensor is not None:\n",
    "        return self.model.output\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        return self.model(input_tensor)\n",
    "    \n",
    "    def tf_summary(self):\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def save(self, filename):\n",
    "        self.model.save_weights(str(filename) + \".h5\")\n",
    "        print(\"Model saved to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_cnn = CNN(tf.Variable(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_11 (InputLayer)            (None, 32, 100, 1)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_43 (Convolution2D) (None, 32, 100, 64)   1664        input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_25 (MaxPooling2D)   (None, 16, 50, 64)    0           convolution2d_43[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_44 (Convolution2D) (None, 16, 50, 128)   204928      maxpooling2d_25[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_26 (MaxPooling2D)   (None, 8, 25, 128)    0           convolution2d_44[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_45 (Convolution2D) (None, 8, 25, 256)    295168      maxpooling2d_26[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_27 (MaxPooling2D)   (None, 4, 12, 256)    0           convolution2d_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_46 (Convolution2D) (None, 4, 12, 512)    1180160     maxpooling2d_27[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_47 (Convolution2D) (None, 4, 12, 512)    2359808     convolution2d_46[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 24576)         0           convolution2d_47[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dense_179 (Dense)                (None, 4096)          100667392   flatten_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 4096)          0           dense_179[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_180 (Dense)                (None, 4096)          16781312    dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_181 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_182 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_183 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_184 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_185 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_186 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_187 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_188 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_189 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_190 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_191 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_192 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_193 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_194 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_195 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_196 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_197 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_198 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_199 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_200 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_201 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_202 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_203 (Dense)                (None, 37)            151589      dense_180[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 124,976,979\n",
      "Trainable params: 124,976,979\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_cnn.tf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk\n"
     ]
    }
   ],
   "source": [
    "model_cnn.save('model_null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model_cnn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = predict_batch(\"try\", (32, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLen = 23\n",
    "def word_to_labels(w):\n",
    "    return list(w) + [\" \"]*(maxLen - len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = \"0123456789abcdefghijklmnopqrstuvwxyz \"\n",
    "V = len(list(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(tokenized_sequences):\n",
    "    rev_vocabulary = []\n",
    "    unique_tokens = set()\n",
    "    for tokens in tokenized_sequences:\n",
    "        unique_tokens.update(tokens)\n",
    "    rev_vocabulary += sorted(unique_tokens)\n",
    "    vocabulary = {}\n",
    "    for i, token in enumerate(rev_vocabulary):\n",
    "        vocabulary[token] = i\n",
    "    return vocabulary, rev_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary, rev_vocabulary = build_vocabulary(list(alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vectorize(w):\n",
    "    letters = word_to_labels(w)\n",
    "    vector = np.zeros((maxLen,V))\n",
    "    for i, letter in enumerate(letters) :\n",
    "        vector[i,vocabulary[letter]]=1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 37)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize('abcade').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = []\n",
    "labels = []\n",
    "for word in y :\n",
    "    #v = vectorize(word)\n",
    "    Y.append(vectorize(word))\n",
    "    \n",
    "# Y.append(vectorize(word))\n",
    "Y = np.array(Y)\n",
    "Y = np.rollaxis(Y,1)\n",
    "#Y = Y.T\n",
    "Y_ = []\n",
    "for row in Y:\n",
    "    Y_.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = vectorize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 523, 37)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split \n",
    "#X, y = predict_batch(\"try\", (32, 100))\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#...     X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples, validate on 53 samples\n",
      "Epoch 1/15\n",
      "81s - loss: 120.9547 - dense_181_loss: 13.4220 - dense_182_loss: 12.1586 - dense_183_loss: 13.3131 - dense_184_loss: 13.4676 - dense_185_loss: 13.2484 - dense_186_loss: 12.4473 - dense_187_loss: 13.7342 - dense_188_loss: 8.2421 - dense_189_loss: 6.0816 - dense_190_loss: 4.2640 - dense_191_loss: 2.5836 - dense_192_loss: 1.4176 - dense_193_loss: 1.0747 - dense_194_loss: 0.8689 - dense_195_loss: 0.6289 - dense_196_loss: 0.5260 - dense_197_loss: 0.5260 - dense_198_loss: 0.4917 - dense_199_loss: 0.4917 - dense_200_loss: 0.4917 - dense_201_loss: 0.4917 - dense_202_loss: 0.4917 - dense_203_loss: 0.4917 - dense_181_acc: 0.0596 - dense_182_acc: 0.1362 - dense_183_acc: 0.0660 - dense_184_acc: 0.0681 - dense_185_acc: 0.0723 - dense_186_acc: 0.1255 - dense_187_acc: 0.0489 - dense_188_acc: 0.3830 - dense_189_acc: 0.5191 - dense_190_acc: 0.6298 - dense_191_acc: 0.7362 - dense_192_acc: 0.8149 - dense_193_acc: 0.8298 - dense_194_acc: 0.8596 - dense_195_acc: 0.8638 - dense_196_acc: 0.8660 - dense_197_acc: 0.8617 - dense_198_acc: 0.8638 - dense_199_acc: 0.8638 - dense_200_acc: 0.8638 - dense_201_acc: 0.8638 - dense_202_acc: 0.8660 - dense_203_acc: 0.8638 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 2/15\n",
      "65s - loss: 128.0532 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.0207 - dense_185_loss: 14.8492 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0681 - dense_185_acc: 0.0787 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 3/15\n",
      "64s - loss: 128.0874 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.1579 - dense_185_loss: 14.7463 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0596 - dense_185_acc: 0.0851 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 4/15\n",
      "107s - loss: 127.9846 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.0207 - dense_185_loss: 14.7463 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1565 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0681 - dense_185_acc: 0.0851 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4319 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 5/15\n",
      "108s - loss: 127.9503 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.0550 - dense_185_loss: 14.7121 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0660 - dense_185_acc: 0.0872 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 6/15\n",
      "108s - loss: 128.0532 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.1922 - dense_185_loss: 14.6778 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0574 - dense_185_acc: 0.0894 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 7/15\n",
      "112s - loss: 127.8817 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 14.9864 - dense_185_loss: 14.7121 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0702 - dense_185_acc: 0.0872 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 8/15\n",
      "77s - loss: 128.0532 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.0893 - dense_185_loss: 14.7806 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0638 - dense_185_acc: 0.0830 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 9/15\n",
      "104s - loss: 127.8131 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 14.9521 - dense_185_loss: 14.6778 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0723 - dense_185_acc: 0.0894 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 10/15\n",
      "127s - loss: 127.9160 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 14.9521 - dense_185_loss: 14.7806 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0723 - dense_185_acc: 0.0830 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 11/15\n",
      "129s - loss: 128.1217 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.2265 - dense_185_loss: 14.7121 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0553 - dense_185_acc: 0.0872 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 12/15\n",
      "132s - loss: 128.1903 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.3293 - dense_185_loss: 14.6778 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0489 - dense_185_acc: 0.0894 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 13/15\n",
      "105s - loss: 127.9846 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.0893 - dense_185_loss: 14.7121 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0638 - dense_185_acc: 0.0872 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 14/15\n",
      "115s - loss: 128.0531 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 15.1579 - dense_185_loss: 14.7121 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0596 - dense_185_acc: 0.0872 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n",
      "Epoch 15/15\n",
      "119s - loss: 127.8474 - dense_181_loss: 15.0207 - dense_182_loss: 13.9919 - dense_183_loss: 14.8835 - dense_184_loss: 14.9521 - dense_185_loss: 14.7121 - dense_186_loss: 13.9576 - dense_187_loss: 15.5351 - dense_188_loss: 9.1222 - dense_189_loss: 6.4815 - dense_190_loss: 4.3210 - dense_191_loss: 2.4692 - dense_192_loss: 1.0631 - dense_193_loss: 0.6516 - dense_194_loss: 0.4115 - dense_195_loss: 0.1715 - dense_196_loss: 0.0686 - dense_197_loss: 0.0343 - dense_198_loss: 1.1921e-07 - dense_199_loss: 1.1921e-07 - dense_200_loss: 1.1921e-07 - dense_201_loss: 1.1921e-07 - dense_202_loss: 1.1921e-07 - dense_203_loss: 1.1921e-07 - dense_181_acc: 0.0681 - dense_182_acc: 0.1319 - dense_183_acc: 0.0766 - dense_184_acc: 0.0723 - dense_185_acc: 0.0872 - dense_186_acc: 0.1340 - dense_187_acc: 0.0362 - dense_188_acc: 0.4340 - dense_189_acc: 0.5979 - dense_190_acc: 0.7319 - dense_191_acc: 0.8468 - dense_192_acc: 0.9340 - dense_193_acc: 0.9596 - dense_194_acc: 0.9745 - dense_195_acc: 0.9894 - dense_196_acc: 0.9957 - dense_197_acc: 0.9979 - dense_198_acc: 1.0000 - dense_199_acc: 1.0000 - dense_200_acc: 1.0000 - dense_201_acc: 1.0000 - dense_202_acc: 1.0000 - dense_203_acc: 1.0000 - val_loss: 127.7283 - val_dense_181_loss: 15.2058 - val_dense_182_loss: 13.9893 - val_dense_183_loss: 14.9016 - val_dense_184_loss: 14.9016 - val_dense_185_loss: 14.2934 - val_dense_186_loss: 14.9016 - val_dense_187_loss: 15.2058 - val_dense_188_loss: 8.8193 - val_dense_189_loss: 6.6905 - val_dense_190_loss: 2.7370 - val_dense_191_loss: 2.4329 - val_dense_192_loss: 1.8247 - val_dense_193_loss: 1.5206 - val_dense_194_loss: 0.3041 - val_dense_195_loss: 1.1921e-07 - val_dense_196_loss: 1.1921e-07 - val_dense_197_loss: 1.1921e-07 - val_dense_198_loss: 1.1921e-07 - val_dense_199_loss: 1.1921e-07 - val_dense_200_loss: 1.1921e-07 - val_dense_201_loss: 1.1921e-07 - val_dense_202_loss: 1.1921e-07 - val_dense_203_loss: 1.1921e-07 - val_dense_181_acc: 0.0566 - val_dense_182_acc: 0.1321 - val_dense_183_acc: 0.0755 - val_dense_184_acc: 0.0755 - val_dense_185_acc: 0.1132 - val_dense_186_acc: 0.0755 - val_dense_187_acc: 0.0566 - val_dense_188_acc: 0.4528 - val_dense_189_acc: 0.5849 - val_dense_190_acc: 0.8302 - val_dense_191_acc: 0.8491 - val_dense_192_acc: 0.8868 - val_dense_193_acc: 0.9057 - val_dense_194_acc: 0.9811 - val_dense_195_acc: 1.0000 - val_dense_196_acc: 1.0000 - val_dense_197_acc: 1.0000 - val_dense_198_acc: 1.0000 - val_dense_199_acc: 1.0000 - val_dense_200_acc: 1.0000 - val_dense_201_acc: 1.0000 - val_dense_202_acc: 1.0000 - val_dense_203_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x37daf0cc0>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_cnn.model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X, Y_,\n",
    "          batch_size=64, nb_epoch=15, \n",
    "          validation_split=0.1,shuffle=True, verbose=2)\n",
    "#model.metrics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = model.predict(X[112:113])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baariel                \n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "for i in range(23):\n",
    "    s += rev_vocabulary[np.where(y[i][0]==1)[0][0]]\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
